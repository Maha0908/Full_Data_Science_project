# -*- coding: utf-8 -*-
"""LOAN_CLASSIFICATION_Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1j2NVotqtfFUjXxtEMUBX-P26VMtqtFd9

**LOAD DATA**
"""

import pandas as pd

df=pd.read_csv('/content/loan.csv')

"""**DATA CLEANING**"""

df.info()

df.head(2)

"""**HANDLE THE NULL VALUES**"""

df.isnull().sum()

"""**VISUALIZING THE MISSING VALUES USING BAR**



"""

import missingno as msno
msno.bar(df)

"""FILL THE NULL VALUES USING IMPUTER"""

from sklearn.impute import SimpleImputer
imputer=SimpleImputer()

imputer.fit(df[['Credit_History']])
df['Credit_History'] = imputer.transform(df[['Credit_History']])

imputer.fit(df[['LoanAmount']])
df['LoanAmount'] = imputer.transform(df[['LoanAmount']])
imputer.fit(df[['Loan_Amount_Term']])
df['Loan_Amount_Term'] = imputer.transform(df[['Loan_Amount_Term']])
imputer.fit(df[['Credit_History']])
df['Credit_History'] = imputer.transform(df[['Credit_History']])

df['Gender'] = df['Gender'].fillna('Other')
df['Married'] = df['Married'].fillna('Other')
df['Self_Employed'] = df['Self_Employed'].fillna('Other')

df.isnull().sum()

df = df.drop('Loan_ID',axis=1)

df.head(2)

"""**CREATING DUMMIES FOR THE COLUMNS**"""

dfm = pd.get_dummies(df['Gender']).astype(int)
df = pd.concat([df,dfm],axis=1)
df = df.drop('Gender',axis=1)

dfm = pd.get_dummies(df['Married']).astype(int)
df = pd.concat([df,dfm],axis=1)
df = df.drop('Married',axis=1)

dfm = pd.get_dummies(df['Education']).astype(int)
df = pd.concat([df,dfm],axis=1)
df = df.drop('Education',axis=1)

dfm = pd.get_dummies(df['Self_Employed']).astype(int)
df = pd.concat([df,dfm],axis=1)
df = df.drop('Self_Employed',axis=1)

dfm = pd.get_dummies(df['Property_Area']).astype(int)
df = pd.concat([df,dfm],axis=1)
df = df.drop('Property_Area',axis=1)

df.columns

df.describe()

"""**EXTRACTING X  AS FEATURES AND Y AS TARGET VALUES**"""

X=df[['Dependents', 'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount',
       'Loan_Amount_Term', 'Credit_History', 'Female', 'Male',
       'Other', 'No', 'Other', 'Yes', 'No', 'Other', 'Yes', 'Rural',
       'Semiurban', 'Urban', 'Graduate', 'Not Graduate']]

y=df['Loan_Status']

y.value_counts()

"""**EXPLORATARY ANALYSIS**

"""

#univariate analysis
import plotly.express as px
px.histogram(df, x='ApplicantIncome', y='LoanAmount')

!pip install seaborn
#Bi variate analysis
import seaborn as sns
sns.scatterplot(df, x='ApplicantIncome', y='LoanAmount')

sns.regplot(df,x='ApplicantIncome', y='LoanAmount')

#correlation
df[['ApplicantIncome','LoanAmount']].corr()

"""**SPLITTING THE FEATURES AND TARGET**"""

from sklearn.model_selection import train_test_split

X_train,X_test,y_train,y_test=train_test_split(X,y,train_size=0.80)

"""**USING K NEAREST NEIGHBORS**"""

from sklearn.neighbors import KNeighborsClassifier
knn=KNeighborsClassifier(n_neighbors=2)
knn.fit(X_train,y_train)
y_pred=knn.predict(X_test)
from sklearn.metrics import classification_report
print(classification_report(y_test,y_pred))

k=[2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]
for i in k:
  from sklearn.neighbors import KNeighborsClassifier
  knn=KNeighborsClassifier(n_neighbors=2)
  knn.fit(X_train,y_train)
  y_pred=knn.predict(X_test)
  from sklearn.metrics import classification_report
  print(i)
  print(classification_report(y_test,y_pred))

"""**USING LOGISTIC REGRESSION**"""

from sklearn.linear_model import LogisticRegression
lr=LogisticRegression()
lr.fit(X_train,y_train)
y_pred=lr.predict(X_test)
from sklearn.metrics import classification_report
print(classification_report(y_test,y_pred))

"""**LOGISTIC REGRESSION IS GOOD MODEL BECAUSE ACCURACY IS MORE COMPARE TO KNN**
In logistic regression  accuracy is 0.76
In KNN accuracy is 0.50

"""